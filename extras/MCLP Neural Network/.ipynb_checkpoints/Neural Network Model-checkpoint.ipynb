{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from scipy.stats import moment\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Flatten, Dense, Add, Input, Activation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.utils import to_categorical\n",
    "from random import seed\n",
    "from matplotlib import pyplot as plt\n",
    "seed(0)\n",
    "\n",
    "#from tensorflow.python.client import device_lib\n",
    "#print(device_lib.list_local_devices()[1])\n",
    "\n",
    "#from keras import backend as K\n",
    "#K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Format data:\n",
    "#argumentos del comando\n",
    "#volumen\n",
    "#nb boxes\n",
    "#nb spaces\n",
    "#volumenes de cajas\n",
    "#L de cajas\n",
    "#W de cajas\n",
    "#H de cajas\n",
    "#volumenes de espacios\n",
    "#L de espacios\n",
    "#W de espacios\n",
    "#H de espacios\n",
    "#volumen alcanzado (BSG 500s)\n",
    "\n",
    "def read_txt(path):\n",
    "    txt = open(path)\n",
    "    data = (txt.read()).split('\\n')\n",
    "    txt.close()\n",
    "    return data\n",
    "\n",
    "def sample_list(data):\n",
    "    sample_list = []\n",
    "    for line in data:\n",
    "        if ':' in line:\n",
    "            sample = []\n",
    "            sample_list.append(sample)\n",
    "        if line != '':\n",
    "            sample.append(line)\n",
    "    return sample_list\n",
    "\n",
    "def get_features(txt_sample_list):\n",
    "    args = []\n",
    "    state_volume = []\n",
    "    nb_boxes = []\n",
    "    nb_spaces = []\n",
    "    boxes_volume = []\n",
    "    l_boxes = []\n",
    "    w_boxes = []\n",
    "    h_boxes = []\n",
    "    spaces_volume = []\n",
    "    l_spaces = []\n",
    "    w_spaces = []\n",
    "    h_spaces = []\n",
    "    volume_reached = []\n",
    "\n",
    "    for file in txt_sample_list:\n",
    "        for feature in file:\n",
    "            if len(feature) == 13:\n",
    "                args.append(feature[0])\n",
    "                state_volume.append(float(feature[1]))\n",
    "                nb_boxes.append(float(feature[2]))\n",
    "                nb_spaces.append(float(feature[3]))\n",
    "                boxes_volume.append(get_array_features(feature, 4))\n",
    "                l_boxes.append(get_array_features(feature, 5))\n",
    "                w_boxes.append(get_array_features(feature, 6))\n",
    "                h_boxes.append(get_array_features(feature, 7))\n",
    "                spaces_volume.append(get_array_features(feature, 8))\n",
    "                l_spaces.append(get_array_features(feature, 9))\n",
    "                w_spaces.append(get_array_features(feature, 10))\n",
    "                h_spaces.append(get_array_features(feature, 11))\n",
    "                volume_reached.append(float(feature[12]))\n",
    "            else:\n",
    "                print('Sample', feature[0].split(':')[0], 'has not been imported')\n",
    "    \n",
    "    return np.array(args), np.array(state_volume), np.array(nb_boxes), np.array(nb_spaces), np.array(boxes_volume), np.array(l_boxes), np.array(w_boxes), np.array(h_boxes), np.array(spaces_volume), np.array(l_spaces), np.array(w_spaces), np.array(h_spaces), np.array(volume_reached)\n",
    "\n",
    "def get_array_features(feature, index):\n",
    "    aux = np.array(feature[index].strip().split(' ')).astype('float32')\n",
    "    aux = np.array([np.mean(aux), moment(aux, moment=2), moment(aux, moment=3), moment(aux, moment=4), moment(aux, moment=5)])\n",
    "    return (aux - np.amin(aux)) / (np.amax(aux) - np.amin(aux)) if np.amin(aux) > 0 and np.amax(aux) > 0 else aux\n",
    "\n",
    "def process_data(state_volume, nb_boxes, nb_spaces, boxes_volume, l_boxes, w_boxes, h_boxes, spaces_volume, l_spaces, w_spaces, h_spaces):\n",
    "    data = []\n",
    "    for file in range(0, len(boxes_volume)):\n",
    "        data.append(np.concatenate((state_volume[file], nb_boxes[file], nb_spaces[file], boxes_volume[file], l_boxes[file], w_boxes[file], h_boxes[file], spaces_volume[file], l_spaces[file], w_spaces[file], h_spaces[file]), axis=None))\n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def export_test_metrics(first_it, last_it, list_test_metrics, random_state, name_metrics):\n",
    "    output = ''\n",
    "    for name in name_metrics:\n",
    "        output += str(name) + '\\t'\n",
    "    output += '\\n'\n",
    "    for metrics in list_test_metrics:\n",
    "        print(metrics)\n",
    "        print(np.ravel(np.array(metrics)))\n",
    "        for m in metrics:\n",
    "            output += str(m) + '\\t'\n",
    "        output += '\\n'\n",
    "    file = open('metrics' + str(first_it) + 'to' + str(last_it) + 'random_state' + str(random_state) + '.txt','w')\n",
    "    file.write(output)\n",
    "    file.close()\n",
    "    print('Metrics save in:', os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def export_scores(first_it, last_it, list_scores, random_state):\n",
    "    output = ''\n",
    "    for score in list_scores:\n",
    "        output = '{\\nhidden layer:[' + str(score[0]) + ', ' + str(score[1]) + ']\\nscore:' + str(score[2].history) + '\\n}\\n'\n",
    "    file = open('scores' + str(first_it) + 'to' + str(last_it) + 'random_state' + str(random_state) + '.json','w')\n",
    "    file.write(output)\n",
    "    file.close()\n",
    "    print('Scores save in:', os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1))\n",
    "\n",
    "def neural_network_model(histogram_data, volume_reached, first_it, last_it, random_state, epochs):\n",
    "    \n",
    "    print('Processed data shape:', processed_data.shape, end='\\n\\n')\n",
    "    print('Volume reached shape:', volume_reached.shape, end='\\n\\n')\n",
    "    \n",
    "    for split in range(0, random_state + 1):\n",
    "        x_train, x_test, y_train, y_test = train_test_split(histogram_data, volume_reached, test_size=0.25, random_state=split)\n",
    "\n",
    "        print('x train shape:', x_train.shape)\n",
    "        print('x test shape:', x_test.shape)\n",
    "        print('y train shape:', y_train.shape)\n",
    "        print('y test shape:', y_test.shape)\n",
    "        print()\n",
    "\n",
    "        scores = []\n",
    "        test_metrics = []\n",
    "\n",
    "        print('Starting Dense Neural Network')\n",
    "        print('Start time:', time.asctime(time.localtime(time.time())))\n",
    "\n",
    "        for i in range(first_it, last_it + 1):\n",
    "            for j in range(first_it, 3):\n",
    "                print('Iteration: i =', i, 'j =', j)\n",
    "                model = Sequential()\n",
    "                model.add(Dense(i, input_dim=histogram_data.shape[1]))\n",
    "                model.add(Activation('tanh'))\n",
    "                model.add(Dense(j))\n",
    "                model.add(Activation('tanh'))\n",
    "                model.add(Dense(1))\n",
    "                model.add(Activation('linear'))\n",
    "                model.compile(loss='mae',\n",
    "                              optimizer='adam',\n",
    "                              metrics=['mse', root_mean_squared_error,'mae'])\n",
    "\n",
    "                model.summary()\n",
    "\n",
    "                scores.append([i, j, np.array(model.fit(x_train, y_train, epochs=epochs))])\n",
    "                test_metrics.append([i, j, model.evaluate(x_test, y_test)])\n",
    "                \n",
    "                #if j % 25 == 0:\n",
    "                export_test_metrics(first_it, last_it, test_metrics, random_state, ['hidden_layer_0', 'hidden_layer_1', 'loss_mae', 'mse', 'root_mean_squared_error','mae'])\n",
    "                export_scores(first_it, last_it, scores, random_state)\n",
    "                del test_metrics\n",
    "                del scores\n",
    "        \n",
    "                del model\n",
    "                K.clear_session()\n",
    "\n",
    "        '''export_test_metrics(first_it, last_it, test_metrics, random_state, ['hidden_layer_0', 'hidden_layer_1', 'loss_msre', 'accuracy', 'mse', 'root_mean_squared_error','mae'])\n",
    "        export_scores(first_it, last_it, scores, random_state)'''\n",
    "\n",
    "        '''del test_metrics\n",
    "        del scores'''\n",
    "\n",
    "        print('End time:', time.asctime(time.localtime(time.time())), end='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_processed_data(processed_data):\n",
    "    output = ''\n",
    "    for sample in processed_data:\n",
    "        for feature in sample:\n",
    "            output += str(feature) + '\\t'\n",
    "        output += '\\n'\n",
    "        \n",
    "    file = open('processed_data' + str(len(processed_data)) + '.txt','w')\n",
    "    file.write(output)\n",
    "    file.close()\n",
    "    print('Processed data save in:', os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 15 has not been imported\n",
      "Sample 24 has not been imported\n",
      "Sample 29 has not been imported\n",
      "Sample 32 has not been imported\n",
      "Sample 45 has not been imported\n",
      "Sample 50 has not been imported\n",
      "Sample 52 has not been imported\n",
      "Sample 61 has not been imported\n",
      "Sample 71 has not been imported\n",
      "Sample 90 has not been imported\n",
      "Sample 95 has not been imported\n",
      "Sample 99 has not been imported\n",
      "Sample 110 has not been imported\n",
      "Sample 147 has not been imported\n",
      "Sample 155 has not been imported\n",
      "Sample 157 has not been imported\n",
      "Sample 158 has not been imported\n",
      "Sample 164 has not been imported\n",
      "Sample 177 has not been imported\n",
      "Sample 178 has not been imported\n",
      "Sample 183 has not been imported\n",
      "Sample 196 has not been imported\n",
      "Sample 202 has not been imported\n",
      "Sample 208 has not been imported\n",
      "Sample 217 has not been imported\n",
      "Sample 225 has not been imported\n",
      "Sample 226 has not been imported\n",
      "Sample 234 has not been imported\n",
      "Sample 243 has not been imported\n",
      "Sample 247 has not been imported\n",
      "Sample 261 has not been imported\n",
      "Sample 262 has not been imported\n",
      "Sample 277 has not been imported\n",
      "Sample 278 has not been imported\n",
      "Sample 284 has not been imported\n",
      "Sample 295 has not been imported\n",
      "Sample 303 has not been imported\n",
      "Sample 322 has not been imported\n",
      "Sample 328 has not been imported\n",
      "Sample 340 has not been imported\n",
      "Sample 347 has not been imported\n",
      "Sample 364 has not been imported\n",
      "Sample 365 has not been imported\n",
      "Sample 377 has not been imported\n",
      "Sample 395 has not been imported\n",
      "Sample 397 has not been imported\n",
      "Sample 403 has not been imported\n",
      "Sample 417 has not been imported\n",
      "Sample 418 has not been imported\n",
      "Sample 442 has not been imported\n",
      "Sample 448 has not been imported\n",
      "Sample 450 has not been imported\n",
      "Sample 458 has not been imported\n",
      "Sample 467 has not been imported\n",
      "Sample 472 has not been imported\n",
      "Sample 478 has not been imported\n",
      "Sample 482 has not been imported\n",
      "Sample 496 has not been imported\n",
      "Sample 497 has not been imported\n",
      "Sample 501 has not been imported\n",
      "Sample 523 has not been imported\n",
      "Sample 529 has not been imported\n",
      "Sample 530 has not been imported\n",
      "Sample 535 has not been imported\n",
      "Sample 547 has not been imported\n",
      "Sample 548 has not been imported\n",
      "Sample 549 has not been imported\n",
      "Sample 570 has not been imported\n",
      "Sample 579 has not been imported\n",
      "Sample 604 has not been imported\n",
      "Sample 618 has not been imported\n",
      "Sample 639 has not been imported\n",
      "Sample 654 has not been imported\n",
      "Sample 655 has not been imported\n",
      "Sample 656 has not been imported\n",
      "Sample 663 has not been imported\n",
      "Sample 665 has not been imported\n",
      "Sample 668 has not been imported\n",
      "Sample 684 has not been imported\n",
      "Sample 689 has not been imported\n",
      "Sample 693 has not been imported\n",
      "Sample 702 has not been imported\n",
      "Sample 3 has not been imported\n",
      "Sample 4 has not been imported\n",
      "Sample 5 has not been imported\n",
      "Sample 10 has not been imported\n",
      "Sample 41 has not been imported\n",
      "Sample 47 has not been imported\n",
      "Sample 53 has not been imported\n",
      "Sample 54 has not been imported\n",
      "Sample 56 has not been imported\n",
      "Sample 62 has not been imported\n",
      "Sample 70 has not been imported\n",
      "Sample 79 has not been imported\n",
      "Sample 93 has not been imported\n",
      "Sample 95 has not been imported\n",
      "Sample 102 has not been imported\n",
      "Sample 113 has not been imported\n",
      "Sample 114 has not been imported\n",
      "Sample 123 has not been imported\n",
      "Sample 130 has not been imported\n",
      "Sample 131 has not been imported\n",
      "Sample 134 has not been imported\n",
      "Sample 142 has not been imported\n",
      "Sample 149 has not been imported\n",
      "Sample 152 has not been imported\n",
      "Sample 155 has not been imported\n",
      "Sample 156 has not been imported\n",
      "Sample 157 has not been imported\n",
      "Sample 159 has not been imported\n",
      "Sample 162 has not been imported\n",
      "Sample 181 has not been imported\n",
      "Sample 185 has not been imported\n",
      "Sample 194 has not been imported\n",
      "Sample 206 has not been imported\n",
      "Sample 209 has not been imported\n",
      "Sample 212 has not been imported\n",
      "Sample 220 has not been imported\n",
      "Sample 222 has not been imported\n",
      "Sample 227 has not been imported\n",
      "Sample 234 has not been imported\n",
      "Sample 251 has not been imported\n",
      "Sample 261 has not been imported\n",
      "Sample 264 has not been imported\n",
      "Sample 276 has not been imported\n",
      "Sample 281 has not been imported\n",
      "Sample 288 has not been imported\n",
      "Sample 322 has not been imported\n",
      "Sample 330 has not been imported\n",
      "Sample 336 has not been imported\n",
      "Sample 338 has not been imported\n",
      "Sample 341 has not been imported\n",
      "Sample 377 has not been imported\n",
      "Sample 390 has not been imported\n",
      "Sample 425 has not been imported\n",
      "Sample 427 has not been imported\n",
      "Sample 440 has not been imported\n",
      "Sample 441 has not been imported\n",
      "Sample 452 has not been imported\n",
      "Sample 456 has not been imported\n",
      "Sample 475 has not been imported\n",
      "Sample 480 has not been imported\n",
      "Sample 489 has not been imported\n",
      "Sample 496 has not been imported\n",
      "Sample 506 has not been imported\n",
      "Sample 525 has not been imported\n",
      "Sample 526 has not been imported\n",
      "Sample 536 has not been imported\n",
      "Sample 546 has not been imported\n",
      "Sample 558 has not been imported\n",
      "Sample 562 has not been imported\n",
      "Sample 568 has not been imported\n",
      "Sample 574 has not been imported\n",
      "Sample 587 has not been imported\n",
      "Sample 589 has not been imported\n",
      "Sample 592 has not been imported\n",
      "Sample 598 has not been imported\n",
      "Sample 616 has not been imported\n",
      "Sample 637 has not been imported\n",
      "Sample 640 has not been imported\n",
      "Sample 664 has not been imported\n",
      "Sample 673 has not been imported\n",
      "Sample 694 has not been imported\n",
      "Sample 4 has not been imported\n",
      "Sample 11 has not been imported\n",
      "Sample 21 has not been imported\n",
      "Sample 26 has not been imported\n",
      "Sample 28 has not been imported\n",
      "Sample 45 has not been imported\n",
      "Sample 46 has not been imported\n",
      "Sample 47 has not been imported\n",
      "Sample 50 has not been imported\n",
      "Sample 52 has not been imported\n",
      "Sample 57 has not been imported\n",
      "Sample 73 has not been imported\n",
      "Sample 89 has not been imported\n",
      "Sample 104 has not been imported\n",
      "Sample 105 has not been imported\n",
      "Sample 111 has not been imported\n",
      "Sample 127 has not been imported\n",
      "Sample 130 has not been imported\n",
      "Sample 134 has not been imported\n",
      "Sample 165 has not been imported\n",
      "Sample 176 has not been imported\n",
      "Sample 180 has not been imported\n",
      "Sample 182 has not been imported\n",
      "Sample 185 has not been imported\n",
      "Sample 190 has not been imported\n",
      "Sample 193 has not been imported\n",
      "Sample 201 has not been imported\n",
      "Sample 203 has not been imported\n",
      "Sample 209 has not been imported\n",
      "Sample 222 has not been imported\n",
      "Sample 225 has not been imported\n",
      "Sample 226 has not been imported\n",
      "Sample 231 has not been imported\n",
      "Sample 243 has not been imported\n",
      "Sample 274 has not been imported\n",
      "Sample 278 has not been imported\n",
      "Sample 283 has not been imported\n",
      "Sample 296 has not been imported\n",
      "Sample 301 has not been imported\n",
      "Sample 313 has not been imported\n",
      "Sample 336 has not been imported\n",
      "Sample 375 has not been imported\n",
      "Sample 382 has not been imported\n",
      "Sample 385 has not been imported\n",
      "Sample 392 has not been imported\n",
      "Sample 396 has not been imported\n",
      "Sample 398 has not been imported\n",
      "Sample 402 has not been imported\n",
      "Sample 410 has not been imported\n",
      "Sample 417 has not been imported\n",
      "Sample 418 has not been imported\n",
      "Sample 421 has not been imported\n",
      "Sample 433 has not been imported\n",
      "Sample 436 has not been imported\n",
      "Sample 445 has not been imported\n",
      "Sample 454 has not been imported\n",
      "Sample 469 has not been imported\n",
      "Sample 484 has not been imported\n",
      "Sample 500 has not been imported\n",
      "Sample 508 has not been imported\n",
      "Sample 509 has not been imported\n",
      "Sample 518 has not been imported\n",
      "Sample 532 has not been imported\n",
      "Sample 549 has not been imported\n",
      "Sample 570 has not been imported\n",
      "Sample 574 has not been imported\n",
      "Sample 594 has not been imported\n",
      "Sample 618 has not been imported\n",
      "Sample 619 has not been imported\n",
      "Sample 623 has not been imported\n",
      "Sample 649 has not been imported\n",
      "Sample 652 has not been imported\n",
      "Sample 658 has not been imported\n",
      "Sample 664 has not been imported\n",
      "Sample 671 has not been imported\n",
      "Sample 693 has not been imported\n",
      "Sample 16 has not been imported\n",
      "Sample 25 has not been imported\n",
      "Sample 35 has not been imported\n",
      "Sample 54 has not been imported\n",
      "Sample 57 has not been imported\n",
      "Sample 59 has not been imported\n",
      "Sample 63 has not been imported\n",
      "Sample 64 has not been imported\n",
      "Sample 67 has not been imported\n",
      "Sample 74 has not been imported\n",
      "Sample 76 has not been imported\n",
      "Sample 77 has not been imported\n",
      "Sample 80 has not been imported\n",
      "Sample 89 has not been imported\n",
      "Sample 96 has not been imported\n",
      "Sample 98 has not been imported\n",
      "Sample 107 has not been imported\n",
      "Sample 111 has not been imported\n",
      "Sample 115 has not been imported\n",
      "Sample 120 has not been imported\n",
      "Sample 126 has not been imported\n",
      "Sample 133 has not been imported\n",
      "Sample 137 has not been imported\n",
      "Sample 138 has not been imported\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 152 has not been imported\n",
      "Sample 155 has not been imported\n",
      "Sample 163 has not been imported\n",
      "Sample 175 has not been imported\n",
      "Sample 176 has not been imported\n",
      "Sample 193 has not been imported\n",
      "Sample 198 has not been imported\n",
      "Sample 206 has not been imported\n",
      "Sample 219 has not been imported\n",
      "Sample 220 has not been imported\n",
      "Sample 225 has not been imported\n",
      "Sample 240 has not been imported\n",
      "Sample 252 has not been imported\n",
      "Sample 253 has not been imported\n",
      "Sample 257 has not been imported\n",
      "Sample 261 has not been imported\n",
      "Sample 267 has not been imported\n",
      "Sample 269 has not been imported\n",
      "Sample 299 has not been imported\n",
      "Sample 307 has not been imported\n",
      "Sample 308 has not been imported\n",
      "Sample 316 has not been imported\n",
      "Sample 317 has not been imported\n",
      "Sample 319 has not been imported\n",
      "Sample 326 has not been imported\n",
      "Sample 339 has not been imported\n",
      "Sample 356 has not been imported\n",
      "Sample 385 has not been imported\n",
      "Sample 393 has not been imported\n",
      "Sample 411 has not been imported\n",
      "Sample 423 has not been imported\n",
      "Sample 435 has not been imported\n",
      "Sample 436 has not been imported\n",
      "Sample 457 has not been imported\n",
      "Sample 458 has not been imported\n",
      "Sample 467 has not been imported\n",
      "Sample 484 has not been imported\n",
      "Sample 486 has not been imported\n",
      "Sample 489 has not been imported\n",
      "Sample 499 has not been imported\n",
      "Sample 523 has not been imported\n",
      "Sample 531 has not been imported\n",
      "Sample 532 has not been imported\n",
      "Sample 533 has not been imported\n",
      "Sample 543 has not been imported\n",
      "Sample 552 has not been imported\n",
      "Sample 557 has not been imported\n",
      "Sample 565 has not been imported\n",
      "Sample 591 has not been imported\n",
      "Sample 598 has not been imported\n",
      "Sample 602 has not been imported\n",
      "Sample 603 has not been imported\n",
      "Sample 621 has not been imported\n",
      "Sample 630 has not been imported\n",
      "Sample 631 has not been imported\n",
      "Sample 634 has not been imported\n",
      "Sample 635 has not been imported\n",
      "Sample 640 has not been imported\n",
      "Sample 648 has not been imported\n",
      "Sample 650 has not been imported\n",
      "Sample 654 has not been imported\n",
      "Sample 669 has not been imported\n",
      "Sample 700 has not been imported\n",
      "Sample 701 has not been imported\n",
      "Sample 7 has not been imported\n",
      "Sample 17 has not been imported\n",
      "Sample 27 has not been imported\n",
      "Sample 30 has not been imported\n",
      "Sample 31 has not been imported\n",
      "Sample 48 has not been imported\n",
      "Sample 56 has not been imported\n",
      "Sample 59 has not been imported\n",
      "Sample 72 has not been imported\n",
      "Sample 77 has not been imported\n",
      "Sample 79 has not been imported\n",
      "Sample 80 has not been imported\n",
      "Sample 83 has not been imported\n",
      "Sample 86 has not been imported\n",
      "Sample 95 has not been imported\n",
      "Sample 100 has not been imported\n",
      "Sample 101 has not been imported\n",
      "Sample 104 has not been imported\n",
      "Sample 105 has not been imported\n",
      "Sample 113 has not been imported\n",
      "Sample 122 has not been imported\n",
      "Sample 124 has not been imported\n",
      "Sample 129 has not been imported\n",
      "Sample 138 has not been imported\n",
      "Sample 160 has not been imported\n",
      "Sample 191 has not been imported\n",
      "Sample 236 has not been imported\n",
      "Sample 244 has not been imported\n",
      "Sample 247 has not been imported\n",
      "Sample 256 has not been imported\n",
      "Sample 258 has not been imported\n",
      "Sample 260 has not been imported\n",
      "Sample 268 has not been imported\n",
      "Sample 271 has not been imported\n",
      "Sample 272 has not been imported\n",
      "Sample 294 has not been imported\n",
      "Sample 318 has not been imported\n",
      "Sample 323 has not been imported\n",
      "Sample 326 has not been imported\n",
      "Sample 328 has not been imported\n",
      "Sample 342 has not been imported\n",
      "Sample 353 has not been imported\n",
      "Sample 407 has not been imported\n",
      "Sample 412 has not been imported\n",
      "Sample 430 has not been imported\n",
      "Sample 433 has not been imported\n",
      "Sample 444 has not been imported\n",
      "Sample 447 has not been imported\n",
      "Sample 449 has not been imported\n",
      "Sample 456 has not been imported\n",
      "Sample 457 has not been imported\n",
      "Sample 460 has not been imported\n",
      "Sample 461 has not been imported\n",
      "Sample 499 has not been imported\n",
      "Sample 515 has not been imported\n",
      "Sample 523 has not been imported\n",
      "Sample 527 has not been imported\n",
      "Sample 538 has not been imported\n",
      "Sample 570 has not been imported\n",
      "Sample 583 has not been imported\n",
      "Sample 591 has not been imported\n",
      "Sample 601 has not been imported\n",
      "Sample 612 has not been imported\n",
      "Sample 616 has not been imported\n",
      "Sample 623 has not been imported\n",
      "Sample 629 has not been imported\n",
      "Sample 637 has not been imported\n",
      "Sample 650 has not been imported\n",
      "Sample 687 has not been imported\n",
      "Sample 690 has not been imported\n",
      "Sample 701 has not been imported\n",
      "Sample 702 has not been imported\n",
      "Sample 1 has not been imported\n",
      "Sample 11 has not been imported\n",
      "Sample 12 has not been imported\n",
      "Sample 16 has not been imported\n",
      "Sample 17 has not been imported\n",
      "Sample 18 has not been imported\n",
      "Sample 19 has not been imported\n",
      "Sample 24 has not been imported\n",
      "Sample 32 has not been imported\n",
      "Sample 33 has not been imported\n",
      "Sample 39 has not been imported\n",
      "Sample 40 has not been imported\n",
      "Sample 58 has not been imported\n",
      "Sample 59 has not been imported\n",
      "Sample 74 has not been imported\n",
      "Sample 86 has not been imported\n",
      "Sample 92 has not been imported\n",
      "Sample 98 has not been imported\n",
      "Sample 100 has not been imported\n",
      "Sample 105 has not been imported\n",
      "Sample 107 has not been imported\n",
      "Sample 129 has not been imported\n",
      "Sample 130 has not been imported\n",
      "Sample 138 has not been imported\n",
      "Sample 139 has not been imported\n",
      "Sample 160 has not been imported\n",
      "Sample 162 has not been imported\n",
      "Sample 172 has not been imported\n",
      "Sample 177 has not been imported\n",
      "Sample 181 has not been imported\n",
      "Sample 189 has not been imported\n",
      "Sample 192 has not been imported\n",
      "Sample 197 has not been imported\n",
      "Sample 199 has not been imported\n",
      "Sample 209 has not been imported\n",
      "Sample 234 has not been imported\n",
      "Sample 240 has not been imported\n",
      "Sample 255 has not been imported\n",
      "Sample 265 has not been imported\n",
      "Sample 271 has not been imported\n",
      "Sample 274 has not been imported\n",
      "Sample 280 has not been imported\n",
      "Sample 288 has not been imported\n",
      "Sample 290 has not been imported\n",
      "Sample 295 has not been imported\n",
      "Sample 307 has not been imported\n",
      "Sample 335 has not been imported\n",
      "Sample 345 has not been imported\n",
      "Sample 368 has not been imported\n",
      "Sample 369 has not been imported\n",
      "Sample 389 has not been imported\n",
      "Sample 399 has not been imported\n",
      "Sample 431 has not been imported\n",
      "Sample 437 has not been imported\n",
      "Sample 444 has not been imported\n",
      "Sample 447 has not been imported\n",
      "Sample 463 has not been imported\n",
      "Sample 468 has not been imported\n",
      "Sample 469 has not been imported\n",
      "Sample 481 has not been imported\n",
      "Sample 483 has not been imported\n",
      "Sample 504 has not been imported\n",
      "Sample 508 has not been imported\n",
      "Sample 521 has not been imported\n",
      "Sample 535 has not been imported\n",
      "Sample 538 has not been imported\n",
      "Sample 548 has not been imported\n",
      "Sample 559 has not been imported\n",
      "Sample 562 has not been imported\n",
      "Sample 566 has not been imported\n",
      "Sample 582 has not been imported\n",
      "Sample 600 has not been imported\n",
      "Sample 614 has not been imported\n",
      "Sample 615 has not been imported\n",
      "Sample 624 has not been imported\n",
      "Sample 627 has not been imported\n",
      "Sample 633 has not been imported\n",
      "Sample 639 has not been imported\n",
      "Sample 644 has not been imported\n",
      "Sample 649 has not been imported\n",
      "Sample 651 has not been imported\n",
      "Sample 654 has not been imported\n",
      "Sample 660 has not been imported\n",
      "Sample 668 has not been imported\n",
      "Sample 671 has not been imported\n",
      "Sample 698 has not been imported\n",
      "Imported data\n",
      "Processed data\n",
      "Processed data save in: C:\\Users\\crist\\anaconda-workspace\\MCLP Neural Network\\02\n"
     ]
    }
   ],
   "source": [
    "with K.tf.device('/gpu:0'):\n",
    "    DATADIR = \"trainingset_allinfo/\"\n",
    "    txt_sample_list = []\n",
    "    for name_txt in os.listdir(DATADIR):\n",
    "        if (\"trainingset_allinfo\" in name_txt and \".txt\" in name_txt) and '~$' not in name_txt:\n",
    "            data = read_txt(DATADIR + name_txt)\n",
    "            txt_sample_list.append(sample_list(data))\n",
    "\n",
    "    args, state_volume, nb_boxes, nb_spaces, boxes_volume, l_boxes, w_boxes, h_boxes, spaces_volume, l_spaces, w_spaces, h_spaces, volume_reached = get_features(txt_sample_list)\n",
    "    print('Imported data')\n",
    "    processed_data = process_data(state_volume, nb_boxes, nb_spaces, boxes_volume, l_boxes, w_boxes, h_boxes, spaces_volume, l_spaces, w_spaces, h_spaces)\n",
    "    print('Processed data')\n",
    "    export_processed_data(processed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shape data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3745,)\n",
      "(3745,)\n",
      "(3745,)\n",
      "(3745,)\n",
      "(3745, 5)\n",
      "(3745, 5)\n",
      "(3745, 5)\n",
      "(3745, 5)\n",
      "(3745, 5)\n",
      "(3745, 5)\n",
      "(3745, 5)\n",
      "(3745, 5)\n",
      "(3745,)\n"
     ]
    }
   ],
   "source": [
    "print(args.shape)\n",
    "print(state_volume.shape)\n",
    "print(nb_boxes.shape)\n",
    "print(nb_spaces.shape)\n",
    "print(boxes_volume.shape)\n",
    "print(l_boxes.shape)\n",
    "print(w_boxes.shape)\n",
    "print(h_boxes.shape)\n",
    "print(spaces_volume.shape)\n",
    "print(l_spaces.shape)\n",
    "print(w_spaces.shape)\n",
    "print(h_spaces.shape)\n",
    "print(volume_reached.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Neural Network Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data shape: (3745, 43)\n",
      "\n",
      "Volume reached shape: (3745,)\n",
      "\n",
      "x train shape: (2808, 43)\n",
      "x test shape: (937, 43)\n",
      "y train shape: (2808,)\n",
      "y test shape: (937,)\n",
      "\n",
      "Starting Dense Neural Network\n",
      "Start time: Sat Sep  7 00:27:03 2019\n",
      "Iteration: i = 2 j = 2\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 2)                 88        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 3         \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 97\n",
      "Trainable params: 97\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/50\n",
      "2808/2808 [==============================] - 8s 3ms/step - loss: 0.8598 - mean_squared_error: 1.0132 - root_mean_squared_error: 0.8598 - mean_absolute_error: 0.8598\n",
      "Epoch 2/50\n",
      "2808/2808 [==============================] - 0s 71us/step - loss: 0.2903 - mean_squared_error: 0.2531 - root_mean_squared_error: 0.2903 - mean_absolute_error: 0.2903\n",
      "Epoch 3/50\n",
      "2808/2808 [==============================] - 0s 73us/step - loss: 0.1553 - mean_squared_error: 0.1454 - root_mean_squared_error: 0.1553 - mean_absolute_error: 0.1553\n",
      "Epoch 4/50\n",
      "2808/2808 [==============================] - 0s 71us/step - loss: 0.0902 - mean_squared_error: 0.0682 - root_mean_squared_error: 0.0902 - mean_absolute_error: 0.0902\n",
      "Epoch 5/50\n",
      "2808/2808 [==============================] - 0s 72us/step - loss: 0.0408 - mean_squared_error: 0.0168 - root_mean_squared_error: 0.0408 - mean_absolute_error: 0.0408\n",
      "Epoch 6/50\n",
      "2808/2808 [==============================] - 0s 72us/step - loss: 0.0158 - mean_squared_error: 0.0030 - root_mean_squared_error: 0.0158 - mean_absolute_error: 0.0158\n",
      "Epoch 7/50\n",
      "2808/2808 [==============================] - 0s 73us/step - loss: 0.0135 - mean_squared_error: 9.4935e-04 - root_mean_squared_error: 0.0135 - mean_absolute_error: 0.0135\n",
      "Epoch 8/50\n",
      "2808/2808 [==============================] - 0s 73us/step - loss: 0.0120 - mean_squared_error: 4.2307e-04 - root_mean_squared_error: 0.0120 - mean_absolute_error: 0.0120\n",
      "Epoch 9/50\n",
      "2808/2808 [==============================] - 0s 70us/step - loss: 0.0121 - mean_squared_error: 4.0550e-04 - root_mean_squared_error: 0.0121 - mean_absolute_error: 0.0121\n",
      "Epoch 10/50\n",
      "2808/2808 [==============================] - 0s 74us/step - loss: 0.0119 - mean_squared_error: 3.7158e-04 - root_mean_squared_error: 0.0119 - mean_absolute_error: 0.0119\n",
      "Epoch 11/50\n",
      "2808/2808 [==============================] - 0s 72us/step - loss: 0.0119 - mean_squared_error: 3.9018e-04 - root_mean_squared_error: 0.0119 - mean_absolute_error: 0.0119\n",
      "Epoch 12/50\n",
      "2808/2808 [==============================] - 0s 71us/step - loss: 0.0121 - mean_squared_error: 3.8372e-04 - root_mean_squared_error: 0.0121 - mean_absolute_error: 0.0121\n",
      "Epoch 13/50\n",
      "2808/2808 [==============================] - 0s 73us/step - loss: 0.0119 - mean_squared_error: 3.7136e-04 - root_mean_squared_error: 0.0119 - mean_absolute_error: 0.0119\n",
      "Epoch 14/50\n",
      "2808/2808 [==============================] - 0s 71us/step - loss: 0.0119 - mean_squared_error: 3.7097e-04 - root_mean_squared_error: 0.0119 - mean_absolute_error: 0.0119\n",
      "Epoch 15/50\n",
      "2808/2808 [==============================] - 0s 73us/step - loss: 0.0119 - mean_squared_error: 3.7647e-04 - root_mean_squared_error: 0.0119 - mean_absolute_error: 0.0119\n",
      "Epoch 16/50\n",
      "2808/2808 [==============================] - 0s 71us/step - loss: 0.0119 - mean_squared_error: 3.6838e-04 - root_mean_squared_error: 0.0119 - mean_absolute_error: 0.0119\n",
      "Epoch 17/50\n",
      "2808/2808 [==============================] - 0s 72us/step - loss: 0.0118 - mean_squared_error: 3.6565e-04 - root_mean_squared_error: 0.0118 - mean_absolute_error: 0.0118\n",
      "Epoch 18/50\n",
      "2808/2808 [==============================] - 0s 73us/step - loss: 0.0120 - mean_squared_error: 3.7189e-04 - root_mean_squared_error: 0.0120 - mean_absolute_error: 0.0120\n",
      "Epoch 19/50\n",
      "2808/2808 [==============================] - 0s 71us/step - loss: 0.0118 - mean_squared_error: 3.6306e-04 - root_mean_squared_error: 0.0118 - mean_absolute_error: 0.0118\n",
      "Epoch 20/50\n",
      "2808/2808 [==============================] - 0s 71us/step - loss: 0.0121 - mean_squared_error: 3.7349e-04 - root_mean_squared_error: 0.0121 - mean_absolute_error: 0.0121\n",
      "Epoch 21/50\n",
      "2808/2808 [==============================] - 0s 74us/step - loss: 0.0119 - mean_squared_error: 3.7236e-04 - root_mean_squared_error: 0.0119 - mean_absolute_error: 0.0119\n",
      "Epoch 22/50\n",
      "2808/2808 [==============================] - 0s 71us/step - loss: 0.0119 - mean_squared_error: 3.5954e-04 - root_mean_squared_error: 0.0119 - mean_absolute_error: 0.0119\n",
      "Epoch 23/50\n",
      "2808/2808 [==============================] - 0s 72us/step - loss: 0.0117 - mean_squared_error: 3.5672e-04 - root_mean_squared_error: 0.0117 - mean_absolute_error: 0.0117\n",
      "Epoch 24/50\n",
      "2808/2808 [==============================] - 0s 69us/step - loss: 0.0118 - mean_squared_error: 3.6466e-04 - root_mean_squared_error: 0.0118 - mean_absolute_error: 0.0118\n",
      "Epoch 25/50\n",
      "2808/2808 [==============================] - 0s 70us/step - loss: 0.0118 - mean_squared_error: 3.5922e-04 - root_mean_squared_error: 0.0118 - mean_absolute_error: 0.0118\n",
      "Epoch 26/50\n",
      "2808/2808 [==============================] - 0s 71us/step - loss: 0.0118 - mean_squared_error: 3.6664e-04 - root_mean_squared_error: 0.0118 - mean_absolute_error: 0.0118\n",
      "Epoch 27/50\n",
      "2808/2808 [==============================] - 0s 70us/step - loss: 0.0117 - mean_squared_error: 3.5524e-04 - root_mean_squared_error: 0.0117 - mean_absolute_error: 0.0117\n",
      "Epoch 28/50\n",
      "2808/2808 [==============================] - 0s 71us/step - loss: 0.0117 - mean_squared_error: 3.5696e-04 - root_mean_squared_error: 0.0117 - mean_absolute_error: 0.0117\n",
      "Epoch 29/50\n",
      "2808/2808 [==============================] - 0s 69us/step - loss: 0.0118 - mean_squared_error: 3.5866e-04 - root_mean_squared_error: 0.0118 - mean_absolute_error: 0.0118\n",
      "Epoch 30/50\n",
      "2808/2808 [==============================] - 0s 72us/step - loss: 0.0117 - mean_squared_error: 3.5486e-04 - root_mean_squared_error: 0.0117 - mean_absolute_error: 0.0117\n",
      "Epoch 31/50\n",
      "2808/2808 [==============================] - 0s 72us/step - loss: 0.0117 - mean_squared_error: 3.5370e-04 - root_mean_squared_error: 0.0117 - mean_absolute_error: 0.0117\n",
      "Epoch 32/50\n",
      "2808/2808 [==============================] - 0s 70us/step - loss: 0.0117 - mean_squared_error: 3.5527e-04 - root_mean_squared_error: 0.0117 - mean_absolute_error: 0.0117\n",
      "Epoch 33/50\n",
      "2808/2808 [==============================] - 0s 72us/step - loss: 0.0117 - mean_squared_error: 3.5274e-04 - root_mean_squared_error: 0.0117 - mean_absolute_error: 0.0117\n",
      "Epoch 34/50\n",
      "2808/2808 [==============================] - 0s 70us/step - loss: 0.0117 - mean_squared_error: 3.5287e-04 - root_mean_squared_error: 0.0117 - mean_absolute_error: 0.0117\n",
      "Epoch 35/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2808/2808 [==============================] - 0s 71us/step - loss: 0.0116 - mean_squared_error: 3.5911e-04 - root_mean_squared_error: 0.0116 - mean_absolute_error: 0.0116\n",
      "Epoch 36/50\n",
      "2808/2808 [==============================] - 0s 68us/step - loss: 0.0115 - mean_squared_error: 3.4340e-04 - root_mean_squared_error: 0.0115 - mean_absolute_error: 0.0115\n",
      "Epoch 37/50\n",
      "2808/2808 [==============================] - 0s 67us/step - loss: 0.0113 - mean_squared_error: 3.3978e-04 - root_mean_squared_error: 0.0113 - mean_absolute_error: 0.0113\n",
      "Epoch 38/50\n",
      "2808/2808 [==============================] - 0s 72us/step - loss: 0.0114 - mean_squared_error: 3.4440e-04 - root_mean_squared_error: 0.0114 - mean_absolute_error: 0.0114\n",
      "Epoch 39/50\n",
      "2808/2808 [==============================] - 0s 69us/step - loss: 0.0114 - mean_squared_error: 3.4625e-04 - root_mean_squared_error: 0.0114 - mean_absolute_error: 0.0114\n",
      "Epoch 40/50\n",
      "2808/2808 [==============================] - 0s 71us/step - loss: 0.0112 - mean_squared_error: 3.3546e-04 - root_mean_squared_error: 0.0112 - mean_absolute_error: 0.0112\n",
      "Epoch 41/50\n",
      "2808/2808 [==============================] - 0s 72us/step - loss: 0.0113 - mean_squared_error: 3.4709e-04 - root_mean_squared_error: 0.0113 - mean_absolute_error: 0.0113\n",
      "Epoch 42/50\n",
      "2808/2808 [==============================] - 0s 69us/step - loss: 0.0110 - mean_squared_error: 3.3092e-04 - root_mean_squared_error: 0.0110 - mean_absolute_error: 0.0110\n",
      "Epoch 43/50\n",
      "2808/2808 [==============================] - 0s 71us/step - loss: 0.0111 - mean_squared_error: 3.3710e-04 - root_mean_squared_error: 0.0111 - mean_absolute_error: 0.0111\n",
      "Epoch 44/50\n",
      "2808/2808 [==============================] - 0s 69us/step - loss: 0.0110 - mean_squared_error: 3.3399e-04 - root_mean_squared_error: 0.0110 - mean_absolute_error: 0.0110\n",
      "Epoch 45/50\n",
      "2808/2808 [==============================] - 0s 69us/step - loss: 0.0108 - mean_squared_error: 3.2809e-04 - root_mean_squared_error: 0.0108 - mean_absolute_error: 0.0108\n",
      "Epoch 46/50\n",
      "2808/2808 [==============================] - 0s 74us/step - loss: 0.0106 - mean_squared_error: 3.2496e-04 - root_mean_squared_error: 0.0106 - mean_absolute_error: 0.0106\n",
      "Epoch 47/50\n",
      "2808/2808 [==============================] - 0s 69us/step - loss: 0.0101 - mean_squared_error: 3.1820e-04 - root_mean_squared_error: 0.0101 - mean_absolute_error: 0.0101\n",
      "Epoch 48/50\n",
      "2808/2808 [==============================] - 0s 70us/step - loss: 0.0094 - mean_squared_error: 2.9470e-04 - root_mean_squared_error: 0.0094 - mean_absolute_error: 0.0094\n",
      "Epoch 49/50\n",
      "2808/2808 [==============================] - 0s 71us/step - loss: 0.0083 - mean_squared_error: 2.6927e-04 - root_mean_squared_error: 0.0083 - mean_absolute_error: 0.0083\n",
      "Epoch 50/50\n",
      "2808/2808 [==============================] - 0s 69us/step - loss: 0.0081 - mean_squared_error: 2.4859e-04 - root_mean_squared_error: 0.0081 - mean_absolute_error: 0.0081\n",
      "937/937 [==============================] - 0s 60us/step\n",
      "[2, 2, [0.008625973569648688, 0.0002106765908428409, 0.008625973569648688, 0.008625973569648688]]\n",
      "[2 2\n",
      " list([0.008625973569648688, 0.0002106765908428409, 0.008625973569648688, 0.008625973569648688])]\n",
      "Metrics save in: C:\\Users\\crist\\anaconda-workspace\\MCLP Neural Network\\02\n",
      "Scores save in: C:\\Users\\crist\\anaconda-workspace\\MCLP Neural Network\\02\n",
      "End time: Sat Sep  7 00:27:22 2019\n",
      "\n",
      "x train shape: (2808, 43)\n",
      "x test shape: (937, 43)\n",
      "y train shape: (2808,)\n",
      "y test shape: (937,)\n",
      "\n",
      "Starting Dense Neural Network\n",
      "Start time: Sat Sep  7 00:27:22 2019\n",
      "Iteration: i = 2 j = 2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 2)                 88        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 3         \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 97\n",
      "Trainable params: 97\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "2808/2808 [==============================] - 0s 132us/step - loss: 0.5664 - mean_squared_error: 0.3489 - root_mean_squared_error: 0.5664 - mean_absolute_error: 0.5664\n",
      "Epoch 2/50\n",
      "2808/2808 [==============================] - 0s 73us/step - loss: 0.2478 - mean_squared_error: 0.0690 - root_mean_squared_error: 0.2478 - mean_absolute_error: 0.2478\n",
      "Epoch 3/50\n",
      "2808/2808 [==============================] - 0s 74us/step - loss: 0.0274 - mean_squared_error: 0.0016 - root_mean_squared_error: 0.0274 - mean_absolute_error: 0.0274\n",
      "Epoch 4/50\n",
      "2808/2808 [==============================] - 0s 70us/step - loss: 0.0116 - mean_squared_error: 3.2604e-04 - root_mean_squared_error: 0.0116 - mean_absolute_error: 0.0116\n",
      "Epoch 5/50\n",
      "2808/2808 [==============================] - 0s 71us/step - loss: 0.0115 - mean_squared_error: 3.2024e-04 - root_mean_squared_error: 0.0115 - mean_absolute_error: 0.0115\n",
      "Epoch 6/50\n",
      "2808/2808 [==============================] - 0s 72us/step - loss: 0.0107 - mean_squared_error: 2.9019e-04 - root_mean_squared_error: 0.0107 - mean_absolute_error: 0.0107\n",
      "Epoch 7/50\n",
      "2808/2808 [==============================] - 0s 71us/step - loss: 0.0085 - mean_squared_error: 2.2974e-04 - root_mean_squared_error: 0.0085 - mean_absolute_error: 0.0085\n",
      "Epoch 8/50\n",
      "2808/2808 [==============================] - 0s 72us/step - loss: 0.0083 - mean_squared_error: 2.1867e-04 - root_mean_squared_error: 0.0083 - mean_absolute_error: 0.0083\n",
      "Epoch 9/50\n",
      "2808/2808 [==============================] - 0s 70us/step - loss: 0.0082 - mean_squared_error: 2.1314e-04 - root_mean_squared_error: 0.0082 - mean_absolute_error: 0.0082\n",
      "Epoch 10/50\n",
      "2808/2808 [==============================] - 0s 69us/step - loss: 0.0081 - mean_squared_error: 2.0932e-04 - root_mean_squared_error: 0.0081 - mean_absolute_error: 0.0081\n",
      "Epoch 11/50\n",
      "2808/2808 [==============================] - 0s 71us/step - loss: 0.0080 - mean_squared_error: 2.0780e-04 - root_mean_squared_error: 0.0080 - mean_absolute_error: 0.0080\n",
      "Epoch 12/50\n",
      "2808/2808 [==============================] - 0s 70us/step - loss: 0.0080 - mean_squared_error: 2.0551e-04 - root_mean_squared_error: 0.0080 - mean_absolute_error: 0.0080\n",
      "Epoch 13/50\n",
      "2808/2808 [==============================] - 0s 69us/step - loss: 0.0080 - mean_squared_error: 2.0613e-04 - root_mean_squared_error: 0.0080 - mean_absolute_error: 0.0080\n",
      "Epoch 14/50\n",
      "2808/2808 [==============================] - 0s 70us/step - loss: 0.0080 - mean_squared_error: 2.0575e-04 - root_mean_squared_error: 0.0080 - mean_absolute_error: 0.0080\n",
      "Epoch 15/50\n",
      "2808/2808 [==============================] - 0s 72us/step - loss: 0.0080 - mean_squared_error: 2.0470e-04 - root_mean_squared_error: 0.0080 - mean_absolute_error: 0.0080\n",
      "Epoch 16/50\n",
      "2808/2808 [==============================] - 0s 70us/step - loss: 0.0079 - mean_squared_error: 2.0408e-04 - root_mean_squared_error: 0.0079 - mean_absolute_error: 0.0079\n",
      "Epoch 17/50\n",
      "2808/2808 [==============================] - 0s 71us/step - loss: 0.0077 - mean_squared_error: 1.9676e-04 - root_mean_squared_error: 0.0077 - mean_absolute_error: 0.0077\n",
      "Epoch 18/50\n",
      "2808/2808 [==============================] - 0s 71us/step - loss: 0.0077 - mean_squared_error: 1.9884e-04 - root_mean_squared_error: 0.0077 - mean_absolute_error: 0.0077\n",
      "Epoch 19/50\n",
      "2808/2808 [==============================] - 0s 70us/step - loss: 0.0076 - mean_squared_error: 1.9722e-04 - root_mean_squared_error: 0.0076 - mean_absolute_error: 0.0076\n",
      "Epoch 20/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2808/2808 [==============================] - 0s 70us/step - loss: 0.0076 - mean_squared_error: 1.9611e-04 - root_mean_squared_error: 0.0076 - mean_absolute_error: 0.0076\n",
      "Epoch 21/50\n",
      "2808/2808 [==============================] - 0s 67us/step - loss: 0.0076 - mean_squared_error: 1.9479e-04 - root_mean_squared_error: 0.0076 - mean_absolute_error: 0.0076\n",
      "Epoch 22/50\n",
      "2808/2808 [==============================] - 0s 67us/step - loss: 0.0076 - mean_squared_error: 1.9471e-04 - root_mean_squared_error: 0.0076 - mean_absolute_error: 0.0076\n",
      "Epoch 23/50\n",
      "2808/2808 [==============================] - 0s 70us/step - loss: 0.0075 - mean_squared_error: 1.9382e-04 - root_mean_squared_error: 0.0075 - mean_absolute_error: 0.0075\n",
      "Epoch 24/50\n",
      "2808/2808 [==============================] - 0s 70us/step - loss: 0.0076 - mean_squared_error: 1.9390e-04 - root_mean_squared_error: 0.0076 - mean_absolute_error: 0.0076\n",
      "Epoch 25/50\n",
      "2808/2808 [==============================] - 0s 69us/step - loss: 0.0075 - mean_squared_error: 1.9404e-04 - root_mean_squared_error: 0.0075 - mean_absolute_error: 0.0075\n",
      "Epoch 26/50\n",
      "2808/2808 [==============================] - 0s 71us/step - loss: 0.0075 - mean_squared_error: 1.9259e-04 - root_mean_squared_error: 0.0075 - mean_absolute_error: 0.0075\n",
      "Epoch 27/50\n",
      "2808/2808 [==============================] - 0s 68us/step - loss: 0.0075 - mean_squared_error: 1.9171e-04 - root_mean_squared_error: 0.0075 - mean_absolute_error: 0.0075\n",
      "Epoch 28/50\n",
      "2808/2808 [==============================] - 0s 70us/step - loss: 0.0076 - mean_squared_error: 1.9349e-04 - root_mean_squared_error: 0.0076 - mean_absolute_error: 0.0076\n",
      "Epoch 29/50\n",
      "2808/2808 [==============================] - 0s 70us/step - loss: 0.0075 - mean_squared_error: 1.9131e-04 - root_mean_squared_error: 0.0075 - mean_absolute_error: 0.0075\n",
      "Epoch 30/50\n",
      "2808/2808 [==============================] - 0s 69us/step - loss: 0.0076 - mean_squared_error: 1.9573e-04 - root_mean_squared_error: 0.0076 - mean_absolute_error: 0.0076\n",
      "Epoch 31/50\n",
      "2808/2808 [==============================] - 0s 71us/step - loss: 0.0076 - mean_squared_error: 1.9479e-04 - root_mean_squared_error: 0.0076 - mean_absolute_error: 0.0076\n",
      "Epoch 32/50\n",
      "2808/2808 [==============================] - 0s 69us/step - loss: 0.0075 - mean_squared_error: 1.9069e-04 - root_mean_squared_error: 0.0075 - mean_absolute_error: 0.0075\n",
      "Epoch 33/50\n",
      "2808/2808 [==============================] - 0s 71us/step - loss: 0.0076 - mean_squared_error: 1.9339e-04 - root_mean_squared_error: 0.0076 - mean_absolute_error: 0.0076\n",
      "Epoch 34/50\n",
      "2808/2808 [==============================] - 0s 69us/step - loss: 0.0075 - mean_squared_error: 1.9160e-04 - root_mean_squared_error: 0.0075 - mean_absolute_error: 0.0075\n",
      "Epoch 35/50\n",
      "2808/2808 [==============================] - 0s 71us/step - loss: 0.0076 - mean_squared_error: 1.9192e-04 - root_mean_squared_error: 0.0076 - mean_absolute_error: 0.0076\n",
      "Epoch 36/50\n",
      "2808/2808 [==============================] - 0s 70us/step - loss: 0.0074 - mean_squared_error: 1.9064e-04 - root_mean_squared_error: 0.0074 - mean_absolute_error: 0.0074\n",
      "Epoch 37/50\n",
      "2808/2808 [==============================] - 0s 71us/step - loss: 0.0074 - mean_squared_error: 1.8851e-04 - root_mean_squared_error: 0.0074 - mean_absolute_error: 0.0074\n",
      "Epoch 38/50\n",
      "2808/2808 [==============================] - 0s 69us/step - loss: 0.0075 - mean_squared_error: 1.9019e-04 - root_mean_squared_error: 0.0075 - mean_absolute_error: 0.0075\n",
      "Epoch 39/50\n",
      "2808/2808 [==============================] - 0s 72us/step - loss: 0.0074 - mean_squared_error: 1.8715e-04 - root_mean_squared_error: 0.0074 - mean_absolute_error: 0.0074\n",
      "Epoch 40/50\n",
      "2808/2808 [==============================] - 0s 69us/step - loss: 0.0075 - mean_squared_error: 1.8888e-04 - root_mean_squared_error: 0.0075 - mean_absolute_error: 0.0075\n",
      "Epoch 41/50\n",
      "2808/2808 [==============================] - 0s 72us/step - loss: 0.0074 - mean_squared_error: 1.8737e-04 - root_mean_squared_error: 0.0074 - mean_absolute_error: 0.0074\n",
      "Epoch 42/50\n",
      "2808/2808 [==============================] - 0s 70us/step - loss: 0.0075 - mean_squared_error: 1.8970e-04 - root_mean_squared_error: 0.0075 - mean_absolute_error: 0.0075\n",
      "Epoch 43/50\n",
      "2808/2808 [==============================] - 0s 70us/step - loss: 0.0074 - mean_squared_error: 1.8916e-04 - root_mean_squared_error: 0.0074 - mean_absolute_error: 0.0074\n",
      "Epoch 44/50\n",
      "2808/2808 [==============================] - 0s 70us/step - loss: 0.0075 - mean_squared_error: 1.9162e-04 - root_mean_squared_error: 0.0075 - mean_absolute_error: 0.0075\n",
      "Epoch 45/50\n",
      "2808/2808 [==============================] - 0s 70us/step - loss: 0.0075 - mean_squared_error: 1.9196e-04 - root_mean_squared_error: 0.0075 - mean_absolute_error: 0.0075\n",
      "Epoch 46/50\n",
      "2808/2808 [==============================] - 0s 71us/step - loss: 0.0074 - mean_squared_error: 1.8871e-04 - root_mean_squared_error: 0.0074 - mean_absolute_error: 0.0074\n",
      "Epoch 47/50\n",
      "2808/2808 [==============================] - 0s 69us/step - loss: 0.0075 - mean_squared_error: 1.8826e-04 - root_mean_squared_error: 0.0075 - mean_absolute_error: 0.0075\n",
      "Epoch 48/50\n",
      "2808/2808 [==============================] - 0s 70us/step - loss: 0.0075 - mean_squared_error: 1.8959e-04 - root_mean_squared_error: 0.0075 - mean_absolute_error: 0.0075\n",
      "Epoch 49/50\n",
      "2808/2808 [==============================] - 0s 71us/step - loss: 0.0075 - mean_squared_error: 1.9149e-04 - root_mean_squared_error: 0.0075 - mean_absolute_error: 0.0075\n",
      "Epoch 50/50\n",
      "2808/2808 [==============================] - 0s 71us/step - loss: 0.0074 - mean_squared_error: 1.8852e-04 - root_mean_squared_error: 0.0074 - mean_absolute_error: 0.0074\n",
      "937/937 [==============================] - 0s 56us/step\n",
      "[2, 2, [0.007718304555819408, 0.00023118114778389329, 0.007718304555819408, 0.007718304555819408]]\n",
      "[2 2\n",
      " list([0.007718304555819408, 0.00023118114778389329, 0.007718304555819408, 0.007718304555819408])]\n",
      "Metrics save in: C:\\Users\\crist\\anaconda-workspace\\MCLP Neural Network\\02\n",
      "Scores save in: C:\\Users\\crist\\anaconda-workspace\\MCLP Neural Network\\02\n",
      "End time: Sat Sep  7 00:27:32 2019\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with K.tf.device('/gpu:0'):\n",
    "    #neural_network_model(processed_data, volume_reached, 2, 20, 50)\n",
    "    #neural_network_model(processed_data, volume_reached, 21, 40, 50)\n",
    "    #neural_network_model(processed_data, volume_reached, 41, 60, 50)\n",
    "    #neural_network_model(processed_data, volume_reached, 61, 80, 50)\n",
    "    #neural_network_model(processed_data, volume_reached, 2, 20, 5, 50)\n",
    "    neural_network_model(processed_data, volume_reached, 2, 2, 1, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(scores[0].history.keys())\n",
    "# \"Loss\"\n",
    "#plt.plot(history.history['loss'])\n",
    "#plt.plot(history.history['acc'])\n",
    "#plt.plot(history.history['mean_squared_error'])\n",
    "#plt.plot(scores[0].history['root_mean_squared_error'])\n",
    "#plt.title('model loss')\n",
    "#plt.ylabel('root_mean_squared_error')\n",
    "#plt.xlabel('epoch')\n",
    "#plt.legend(['root_mean_squared_error'], loc='upper left')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Neural Network with parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(processed_data, volume_reached, test_size=0.25, random_state=1)\n",
    "\n",
    "#print(x_train.shape)\n",
    "#print(x_test.shape)\n",
    "#print(y_train.shape)\n",
    "#print(y_test.shape)\n",
    "\n",
    "epochs = 69\n",
    "\n",
    "print('Starting Dense Neural Network')\n",
    "print('Start time:', time.asctime(time.localtime(time.time())))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(86, input_dim=processed_data.shape[1]))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(60))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('linear'))\n",
    "model.compile(loss='mae',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy', 'mse', root_mean_squared_error,'mae'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "scores = model.fit(x_train, y_train, epochs=epochs)\n",
    "test_metrics = model.evaluate(x_test, y_test)\n",
    "\n",
    "del model\n",
    "K.clear_session()\n",
    "\n",
    "#export_test_metrics(first_it, last_it, test_metrics, ['loss_msre', 'accuracy', 'mse', 'root_mean_squared_error','mae'])\n",
    "#export_scores(first_it, last_it, scores)\n",
    "print('End time:', time.asctime(time.localtime(time.time())), end='\\n\\n')\n",
    "print('loss:', test_metrics[0])\n",
    "print('accuracy:', test_metrics[1])\n",
    "print('mse:', test_metrics[2])\n",
    "print('rmse:', test_metrics[3])\n",
    "print('mae:', test_metrics[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kurtosis\n",
    "import numpy as np\n",
    "\n",
    "#Format data:\n",
    "#argumentos del comando\n",
    "#volumen\n",
    "#nb boxes\n",
    "#nb spaces\n",
    "#volumenes de cajas\n",
    "#L de cajas\n",
    "#W de cajas\n",
    "#H de cajas\n",
    "#volumenes de espacios\n",
    "#L de espacios\n",
    "#W de espacios\n",
    "#H de espacios\n",
    "#volumen alcanzado (BSG 500s)\n",
    "\n",
    "a = [0.00652783, 0.00652783, 0.00652783, 0.00652783, 0.00652783, 0.00652783, 0.00652783, 0.00652783, 0.00134, 0.00134, 0.00134, 0.00134, 0.00134, 0.00134, 0.0131466, 0.0131466, 0.00807488, 0.00807488, 0.00356508, 0.00356508, 0.00356508, 0.00356508, 0.00356508, 0.00356508, 0.00286052, 0.00286052, 0.00286052, 0.00286052, 0.00286052, 0.00286052, 0.0148113, 0.0148113, 0.0148113, 0.0148113, 0.0148113, 0.0148113, 0.0148113, 0.00509199, 0.00509199, 0.00509199, 0.00509199, 0.00509199, 0.00509199, 0.00509199, 0.00509199, 0.0183822, 0.0183822, 0.0183822, 0.0183822, 0.0183822, 0.0183822, 0.0183822, 0.0183822, 0.0183822, 0.0136456, 0.0136456, 0.0136456, 0.0136456, 0.0136456, 0.0136456, 0.0136456, 0.0136456, 0.00363235, 0.00363235, 0.00363235, 0.00363235, 0.00363235, 0.00363235, 0.00363235, 0.018735]\n",
    "\n",
    "print(kurtosis(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = np.sum(np.array(a))/len(a)\n",
    "a2 = np.sum(np.array(a)**2)/len(a)\n",
    "a3 = np.sum(np.array(a)**3)/len(a)\n",
    "a4 = np.sum(np.array(a)**4)/len(a)\n",
    "\n",
    "m1 = a1 - a1\n",
    "m2 = a2 - (a1**2)\n",
    "m3 = a3 - 3*a1*a2 + 2*a1**3\n",
    "m4 = a4 - 4*a1*a3 + 6*a1**2*a2 - 3*a1**4\n",
    "print(a1)\n",
    "print(a2)\n",
    "print(a3)\n",
    "print(m4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
